{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse as ap\n",
    "import csv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args\n",
    "# tmd = tech, media and telecom\n",
    "# hc = healthcare\n",
    "# cr = consumer and retail\n",
    "# fig = finnancial institution groups\n",
    "# ind = industrials\n",
    "# pnr = power and natural resources\n",
    "\n",
    "\n",
    "class args:\n",
    "    sector = \"tmd\"\n",
    "    model_save = 'output.txt'\n",
    "    batch_size = 10\n",
    "    train_steps = 500\n",
    "    learning_rate = 0.001\n",
    "    classes = 100\n",
    "    cnn_n1_channels = 10 # I hope this works: 05/04/2020\n",
    "    cnn_n1_kernel = 3\n",
    "    cnn_n2_kernel = 3\n",
    "    cnn_n3_kernel = 3\n",
    "    model = 'simple-cnn'\n",
    "    log_file = 'logfile.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Reading from raw files\n",
    "\n",
    "# retval = os.getcwd()\n",
    "# print(retval)\n",
    "def loadData():\n",
    "    path = \"/mnt/c/Minted/Data\"\n",
    "\n",
    "    path, dirs, files = next(os.walk(path))\n",
    "    num_stocks = len(files) - 1\n",
    "    \n",
    "    print(num_stocks)\n",
    "    \n",
    "    prices = np.zeros((num_stocks, 124))\n",
    "    price_index = 4 # highs\n",
    "    iterations = 0\n",
    "    preds = np.zeros(num_stocks)\n",
    "    \n",
    "    os.chdir(path)\n",
    "    for file in glob.glob(\"*.csv\"): \n",
    "        \n",
    "        # print(\"entered\")\n",
    "        \n",
    "        i = 125\n",
    "        this_prices = np.zeros(124)\n",
    "        with open(file) as csvfile:\n",
    "            readCSV = csv.reader(csvfile, delimiter=',')\n",
    "            for row in readCSV:\n",
    "                ind = (row[price_index].find('$')) + 1\n",
    "                if i == 125:\n",
    "                    i -= 1\n",
    "                    continue\n",
    "                if i == 124:\n",
    "                    preds[iterations] = float(row[price_index][ind:])\n",
    "                    i -= 1\n",
    "                    continue\n",
    "                prices[iterations][i] = float(row[price_index][ind:])\n",
    "                \n",
    "                # print(float(row[price_index][ind:]))\n",
    "                # print(prices[iterations][i])\n",
    "\n",
    "                i -= 1\n",
    "\n",
    "        iterations += 1\n",
    "    \n",
    "    for i in range(num_stocks):\n",
    "        maximum = 0\n",
    "        max_prices = max(prices[i])\n",
    "        if preds[i] > max_prices:\n",
    "            maximum = preds[i]\n",
    "        else:\n",
    "            maximum = max_prices\n",
    "    \n",
    "        prices[i] /= maximum\n",
    "        preds[i] /= maximum\n",
    "    \n",
    "    # print(prices.shape)\n",
    "    # print(prices)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(prices[0])\n",
    "    plt.title(\"AAOI\")\n",
    "    \n",
    "    # print(prices[0])\n",
    "    # print(len(prices[0]))\n",
    "    # print(preds[0])\n",
    "    \n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    dev_data = []\n",
    "    dev_labels = []   \n",
    "    \n",
    "    train_percent = 0.8\n",
    "    # train_num = math.ceil(0.8 * num_stocks)\n",
    "    train_num = math.floor(0.8 * num_stocks)\n",
    "    res = random.sample(range(0, num_stocks), train_num)\n",
    "\n",
    "    for i in range(num_stocks):\n",
    "        if i in res:\n",
    "            train_data.append(prices[i])\n",
    "            train_labels.append(preds[i])\n",
    "        else:\n",
    "            dev_data.append(prices[i])\n",
    "            dev_labels.append(preds[i])\n",
    "    \n",
    "    return train_data, train_labels, dev_data, dev_labels\n",
    "\n",
    "\n",
    "\n",
    "# prices = np.transpose(prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Pre-Processing\n",
    "    # Averaging, getting rid of noise, etc.\n",
    "    # normalization?\n",
    "# def splitData():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = True\n",
    "\n",
    "if not loaded:\n",
    "    train_data, train_labels, dev_data, dev_labels = loadData()\n",
    "    print(len(train_data))\n",
    "    # splitData()\n",
    "    os.chdir(\"/mnt/c/Minted\")\n",
    "    np.save(\"training_data.npy\", train_data)\n",
    "    np.save(\"training_labels.npy\", train_labels)\n",
    "    np.save(\"development_data.npy\", dev_data)\n",
    "    np.save(\"development_labels.npy\", dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"training_data.npy\")\n",
    "train_labels = np.load(\"training_labels.npy\")\n",
    "dev_data = np.load(\"development_data.npy\")\n",
    "dev_labels = np.load(\"development_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.Tensor([i for i in train_data])\n",
    "# # train_data = train_X / 4095.0\n",
    "train_labels = torch.Tensor([i for i in train_labels])\n",
    "\n",
    "dev_data = torch.Tensor([i for i in dev_data])\n",
    "# # test_X = test_X / 4095.0\n",
    "dev_labels = torch.Tensor([i for i in dev_labels])\n",
    "\n",
    "train_labels = train_labels.long()\n",
    "dev_labels = dev_labels.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(torch.nn.Module):\n",
    "    def __init__(self, n1_kern, n2_kern, n3_kern, n1_chan):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # kernel = (n1_kern, n2_kern, n3_kern)\n",
    "        self.conv1 = torch.nn.Conv2d(1, n1_chan, kernel_size=n1_kern)\n",
    "        self.conv2 = torch.nn.Conv2d(n1_chan, 2, kernel_size=n2_kern, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        size = x.size()[0]\n",
    "        x = x.view(size, 1, 31, 4)\n",
    "        Relu1 = F.relu(self.conv1(x))\n",
    "        Relu2 = F.relu(Relu1)\n",
    "        dim3 = Relu2.size()[2]\n",
    "        dim4 = Relu2.size()[3]\n",
    "        pool = nn.MaxPool2d((dim3, dim4), stride=2)\n",
    "        logits = pool(Relu2)\n",
    "        logits = logits.view(logits.size()[0], args.batch_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and predict with neural net\n",
    "net = SimpleCNN(args.cnn_n1_kernel, args.cnn_n2_kernel, args.cnn_n1_channels, args.classes)\n",
    "\n",
    "# Define the optimizer & loss function\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "loss_function = nn.CrossEntropyLoss() # Different Format of y shape\n",
    "def fwd_pass(X, y, train = False, calc_acc = True):\n",
    "    if train:\n",
    "        net.zero_grad()\n",
    "    outputs = net(X)\n",
    "    \n",
    "#     if calc_acc:\n",
    "#         total_matches = 0\n",
    "#         for i in tqdm(range(outputs.shape[0])):\n",
    "#             for j in range(outputs.shape[2]):\n",
    "#                 matches = [torch.argmax(outputs[i,:,j,k]) == y[i,j,k] for k in range(outputs.shape[3])]\n",
    "#                 total_matches += matches.count(True)\n",
    "\n",
    "#         acc = total_matches / (outputs.shape[0]*outputs.shape[2]*outputs.shape[3])\n",
    "#     else:\n",
    "#         acc = 0\n",
    "\n",
    "    acc = 0\n",
    "    acc_outputs = outputs.cpu().detach().numpy()\n",
    "    acc_y = y.cpu().detach().numpy()\n",
    "    \n",
    "    print(outputs)\n",
    "    print(y)\n",
    "    \n",
    "    for i in range(outputs.shape[0]):\n",
    "        acc += np.sum((acc_outputs[i] - acc_y)**2)\n",
    "    \n",
    "    acc /= args.batch_size\n",
    "    \n",
    "    loss = loss_function(outputs,y)\n",
    "    \n",
    "    if train:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return acc, loss\n",
    "    # return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(size = 32, calc_acc = False):\n",
    "    random_start = np.random.randint(len(dev_data) - size)\n",
    "    X,y = dev_data[random_start:random_start+size], dev_labels[random_start:random_start+size]\n",
    "    with torch.no_grad():\n",
    "        val_acc, val_loss = fwd_pass(X,y, calc_acc = calc_acc)\n",
    "        # val_loss = fwd_pass(X,y, calc_acc = calc_acc)\n",
    "    return val_acc, val_loss\n",
    "    # return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-1592715617\n",
      "tensor([[0.6225, 0.2829, 0.1212, 0.4160, 0.7181, 0.0000, 0.2026, 0.4801, 0.0000,\n",
      "         1.2098],\n",
      "        [0.6690, 0.2677, 0.0571, 0.4158, 0.7562, 0.0000, 0.1873, 0.4932, 0.0000,\n",
      "         1.2760],\n",
      "        [0.6425, 0.2730, 0.0644, 0.4405, 0.7171, 0.0000, 0.1887, 0.5000, 0.0000,\n",
      "         1.1608],\n",
      "        [0.6444, 0.2714, 0.1713, 0.4514, 0.7529, 0.0000, 0.2380, 0.5353, 0.0000,\n",
      "         1.2143],\n",
      "        [0.6256, 0.2362, 0.0100, 0.3483, 0.7428, 0.0000, 0.1773, 0.4832, 0.0000,\n",
      "         1.2319],\n",
      "        [0.6710, 0.2685, 0.0969, 0.3990, 0.7492, 0.0000, 0.2055, 0.5174, 0.0000,\n",
      "         1.3062],\n",
      "        [0.6293, 0.2550, 0.0458, 0.3888, 0.7163, 0.0000, 0.1905, 0.4681, 0.0000,\n",
      "         1.2073],\n",
      "        [0.6693, 0.2764, 0.0000, 0.4016, 0.7675, 0.0000, 0.1361, 0.5107, 0.0000,\n",
      "         1.2939],\n",
      "        [0.6720, 0.2851, 0.0520, 0.4312, 0.7581, 0.0000, 0.1821, 0.5438, 0.0000,\n",
      "         1.2811],\n",
      "        [0.6721, 0.2911, 0.0056, 0.4387, 0.7717, 0.0000, 0.1616, 0.5715, 0.0000,\n",
      "         1.2868]], grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 0])\n",
      "tensor([[0.6310, 0.2919, 0.1157, 0.4069, 0.7091, 0.0000, 0.1974, 0.4714, 0.0000,\n",
      "         1.2008],\n",
      "        [0.6784, 0.2771, 0.0511, 0.4070, 0.7471, 0.0000, 0.1814, 0.4838, 0.0000,\n",
      "         1.2664],\n",
      "        [0.6512, 0.2817, 0.0584, 0.4317, 0.7090, 0.0000, 0.1826, 0.4912, 0.0000,\n",
      "         1.1522],\n",
      "        [0.6535, 0.2805, 0.1673, 0.4424, 0.7444, 0.0000, 0.2339, 0.5263, 0.0000,\n",
      "         1.2054],\n",
      "        [0.6347, 0.2452, 0.0036, 0.3393, 0.7337, 0.0000, 0.1704, 0.4740, 0.0000,\n",
      "         1.2227],\n",
      "        [0.6808, 0.2780, 0.0919, 0.3892, 0.7394, 0.0000, 0.2002, 0.5081, 0.0000,\n",
      "         1.2964],\n",
      "        [0.6384, 0.2628, 0.0395, 0.3799, 0.7072, 0.0000, 0.1840, 0.4595, 0.0000,\n",
      "         1.1982],\n",
      "        [0.6789, 0.2861, 0.0000, 0.3920, 0.7581, 0.0000, 0.1276, 0.5010, 0.0000,\n",
      "         1.2843],\n",
      "        [0.6815, 0.2936, 0.0461, 0.4218, 0.7485, 0.0000, 0.1761, 0.5353, 0.0000,\n",
      "         1.2716],\n",
      "        [0.6818, 0.2999, 0.0000, 0.4294, 0.7632, 0.0000, 0.1548, 0.5622, 0.0000,\n",
      "         1.2771]], grad_fn=<ViewBackward>)\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 0])\n",
      "tensor([[0.6933, 0.2887, 0.0000, 0.3808, 0.7273, 0.0000, 0.1637, 0.4795, 0.0000,\n",
      "         1.2697]])\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-abc38722d7b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{MODEL_NAME},{round(time.time(),3)}, {round(float(acc),2)}, {round(float(loss),4)}, {round(float(val_acc),2)}, {round(float(val_loss),4)} \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0;31m# f.write(f\"{MODEL_NAME},{round(time.time(),3)} \\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-abc38722d7b6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0;31m# val_loss = test(size = 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{MODEL_NAME},{round(time.time(),3)}, {round(float(acc),2)}, {round(float(loss),4)}, {round(float(val_acc),2)}, {round(float(val_loss),4)} \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                     \u001b[0;31m# f.write(f\"{MODEL_NAME},{round(time.time(),3)} \\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'tuple'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "MODEL_NAME = f\"model-{int(time.time())}\"\n",
    "\n",
    "net = SimpleCNN(args.cnn_n1_kernel, args.cnn_n2_kernel, args.cnn_n3_kernel, args.cnn_n1_channels)\n",
    "optimizer = optim.Adam(net.parameters(), lr = args.learning_rate)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "print(MODEL_NAME)\n",
    "\n",
    "def train():\n",
    "    # BATCH_SIZE = 100 # 55 to 100 is fine\n",
    "    EPOCHS = 250 # 250 is fine right now\n",
    "    with open(\"model.log\", \"w\") as f:\n",
    "        for epoch in range(EPOCHS):\n",
    "            for i in tqdm(range(0,len(train_data), args.batch_size)):\n",
    "                batch_X = train_data[i:i+args.batch_size]\n",
    "                batch_y = train_labels[i:i+args.batch_size]\n",
    "                \n",
    "                acc, loss = fwd_pass(batch_X, batch_y, train = True)\n",
    "                loss = fwd_pass(batch_X, batch_y, train = True)\n",
    "                if i % 50 == 0:\n",
    "                    val_acc, val_loss = test(size = 1)                    \n",
    "                    # val_loss = test(size = 1)\n",
    "                    f.write(f\"{MODEL_NAME},{round(time.time(),3)}, {round(float(acc),2)}, {round(float(loss),4)}, {round(float(val_acc),2)}, {round(float(val_loss),4)} \\n\")\n",
    "                    # f.write(f\"{MODEL_NAME},{round(time.time(),3)} \\n\")\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 6, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-5ae8a2717724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mcreate_acc_loss_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-5ae8a2717724>\u001b[0m in \u001b[0;36mcreate_acc_loss_graph\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 6, got 2)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "style.use(\"ggplot\")\n",
    "\n",
    "model_name = MODEL_NAME\n",
    "\n",
    "def create_acc_loss_graph(model_name):\n",
    "    contents = open(\"model.log\", \"r\").read().split('\\n')\n",
    "    \n",
    "    times = []\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    \n",
    "    val_accs = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for c in contents:\n",
    "        if model_name in c:\n",
    "            name, timestamp, acc, loss, val_acc, val_loss = c.split(\",\")\n",
    "            times.append(float(timestamp))\n",
    "            accuracies.append(float(acc))\n",
    "            losses.append(float(loss))\n",
    "            val_accs.append(float(val_acc))\n",
    "            val_losses.append(float(val_loss))\n",
    "            \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax1 = plt.subplot2grid((2,1),(0,0))\n",
    "    ax2 = plt.subplot2grid((2,1),(1,0), sharex = ax1)\n",
    "    \n",
    "    ax1.plot(times, accuracies, label = 'acc')\n",
    "    ax1.plot(times, val_accs, label = 'val_acc')\n",
    "    ax1.legend(loc = 2)\n",
    "    \n",
    "    ax2.plot(times, losses, label = 'loss')\n",
    "    ax2.plot(times, val_losses, label = 'val_losses')\n",
    "    ax2.legend(loc = 2)\n",
    "    plt.show()\n",
    "    \n",
    "create_acc_loss_graph(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Post Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pattern model to use in tandem with this (probably separate notebook)\n",
    "# Final predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
