{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmandav1/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jmandav1/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jmandav1/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jmandav1/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jmandav1/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jmandav1/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jmandav1/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jmandav1/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jmandav1/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jmandav1/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jmandav1/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jmandav1/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse as ap\n",
    "import csv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args\n",
    "# tmd = tech, media and telecom\n",
    "# hc = healthcare\n",
    "# cr = consumer and retail\n",
    "# fig = finnancial institution groups\n",
    "# ind = industrials\n",
    "# pnr = power and natural resources\n",
    "\n",
    "\n",
    "class args:\n",
    "    sector = \"tmd\"\n",
    "    model_save = 'output.txt'\n",
    "    batch_size = 10\n",
    "    train_steps = 500\n",
    "    learning_rate = 0.001\n",
    "    classes = 2\n",
    "    cnn_n1_channels = 10 # I hope this works: 05/04/2020\n",
    "    cnn_n1_kernel = 3\n",
    "    cnn_n2_kernel = 3\n",
    "    cnn_n3_kernel = 3\n",
    "    model = 'simple-cnn'\n",
    "    log_file = 'logfile.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Reading from raw files\n",
    "\n",
    "# retval = os.getcwd()\n",
    "# print(retval)\n",
    "def loadData():\n",
    "    path = \"/mnt/c/Minted/Data\"\n",
    "\n",
    "    path, dirs, files = next(os.walk(path))\n",
    "    num_stocks = len(files) - 1\n",
    "    \n",
    "    print(num_stocks)\n",
    "    \n",
    "    prices = np.zeros((num_stocks, 124))\n",
    "    price_index = 4 # highs\n",
    "    iterations = 0\n",
    "    preds = np.zeros(num_stocks)\n",
    "    \n",
    "    os.chdir(path)\n",
    "    for file in glob.glob(\"*.csv\"): \n",
    "        \n",
    "        # print(\"entered\")\n",
    "        \n",
    "        i = 125\n",
    "        this_prices = np.zeros(124)\n",
    "        with open(file) as csvfile:\n",
    "            readCSV = csv.reader(csvfile, delimiter=',')\n",
    "            for row in readCSV:\n",
    "                ind = (row[price_index].find('$')) + 1\n",
    "                if i == 125:\n",
    "                    i -= 1\n",
    "                    continue\n",
    "                if i == 124:\n",
    "                    preds[iterations] = float(row[price_index][ind:])\n",
    "                    i -= 1\n",
    "                    continue\n",
    "                prices[iterations][i] = float(row[price_index][ind:])\n",
    "                \n",
    "                # print(float(row[price_index][ind:]))\n",
    "                # print(prices[iterations][i])\n",
    "\n",
    "                i -= 1\n",
    "\n",
    "        iterations += 1\n",
    "    \n",
    "    for i in range(num_stocks):\n",
    "        maximum = 0\n",
    "        max_prices = max(prices[i])\n",
    "        if preds[i] > max_prices:\n",
    "            maximum = preds[i]\n",
    "        else:\n",
    "            maximum = max_prices\n",
    "    \n",
    "        prices[i] /= maximum\n",
    "        preds[i] /= maximum\n",
    "    \n",
    "    # print(prices.shape)\n",
    "    # print(prices)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(prices[0])\n",
    "    plt.title(\"AAOI\")\n",
    "    \n",
    "    # print(prices[0])\n",
    "    # print(len(prices[0]))\n",
    "    # print(preds[0])\n",
    "    \n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    dev_data = []\n",
    "    dev_labels = []   \n",
    "    \n",
    "    train_percent = 0.8\n",
    "    # train_num = math.ceil(0.8 * num_stocks)\n",
    "    train_num = math.floor(0.8 * num_stocks)\n",
    "    res = random.sample(range(0, num_stocks), train_num)\n",
    "\n",
    "    for i in range(num_stocks):\n",
    "        if i in res:\n",
    "            train_data.append(prices[i])\n",
    "            train_labels.append(preds[i])\n",
    "        else:\n",
    "            dev_data.append(prices[i])\n",
    "            dev_labels.append(preds[i])\n",
    "    \n",
    "    return train_data, train_labels, dev_data, dev_labels\n",
    "\n",
    "\n",
    "\n",
    "# prices = np.transpose(prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Pre-Processing\n",
    "    # Averaging, getting rid of noise, etc.\n",
    "    # normalization?\n",
    "# def splitData():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = True\n",
    "\n",
    "if not loaded:\n",
    "    train_data, train_labels, dev_data, dev_labels = loadData()\n",
    "    print(len(train_data))\n",
    "    # splitData()\n",
    "    os.chdir(\"/mnt/c/Minted\")\n",
    "    np.save(\"training_data.npy\", train_data)\n",
    "    np.save(\"training_labels.npy\", train_labels)\n",
    "    np.save(\"development_data.npy\", dev_data)\n",
    "    np.save(\"development_labels.npy\", dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"training_data.npy\")\n",
    "train_labels = np.load(\"training_labels.npy\")\n",
    "dev_data = np.load(\"development_data.npy\")\n",
    "dev_labels = np.load(\"development_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.Tensor([i for i in train_data])\n",
    "# # train_data = train_X / 4095.0\n",
    "train_labels = torch.Tensor([i for i in train_labels])\n",
    "\n",
    "dev_data = torch.Tensor([i for i in dev_data])\n",
    "# # test_X = test_X / 4095.0\n",
    "dev_labels = torch.Tensor([i for i in dev_labels])\n",
    "\n",
    "train_labels = train_labels.long()\n",
    "dev_labels = dev_labels.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(torch.nn.Module):\n",
    "    def __init__(self, n1_kern, n2_kern, n3_kern, n1_chan):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # kernel = (n1_kern, n2_kern, n3_kern)\n",
    "        self.conv1 = torch.nn.Conv1d(10, n1_chan, kernel_size=n1_kern)\n",
    "        self.conv2 = torch.nn.Conv1d(n1_chan, 2, kernel_size=n2_kern, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        size = x.size()[0]\n",
    "        # x = x.view(size, 124)\n",
    "        Relu1 = F.relu(self.conv1(x))\n",
    "        Relu2 = F.relu(Relu1)\n",
    "        dim3 = Relu2.size()[2]\n",
    "        pool = nn.MaxPool1d(dim3, stride=2)\n",
    "        logits = pool(Relu2)\n",
    "        logits = logits.view(logits.size()[0])\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and predict with neural net\n",
    "net = SimpleCNN(args.cnn_n1_kernel, args.cnn_n2_kernel, args.cnn_n1_channels, args.classes)\n",
    "\n",
    "# Define the optimizer & loss function\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "loss_function = nn.CrossEntropyLoss() # Different Format of y shape\n",
    "def fwd_pass(X, y, train = False, calc_acc = True):\n",
    "    if train:\n",
    "        net.zero_grad()\n",
    "    outputs = net(X)\n",
    "    \n",
    "#     if calc_acc:\n",
    "#         total_matches = 0\n",
    "#         for i in tqdm(range(outputs.shape[0])):\n",
    "#             for j in range(outputs.shape[2]):\n",
    "#                 matches = [torch.argmax(outputs[i,:,j,k]) == y[i,j,k] for k in range(outputs.shape[3])]\n",
    "#                 total_matches += matches.count(True)\n",
    "\n",
    "#         acc = total_matches / (outputs.shape[0]*outputs.shape[2]*outputs.shape[3])\n",
    "#     else:\n",
    "#         acc = 0\n",
    "\n",
    "    acc = 0\n",
    "    acc_outputs = outputs.cpu().detach().numpy()\n",
    "    acc_y = y.cpu().detach().numpy()\n",
    "    \n",
    "    # print(outputs)\n",
    "    # print(y)\n",
    "    \n",
    "    print(acc_outputs.shape)\n",
    "    print(acc_y.shape)\n",
    "    \n",
    "    for i in range(acc_outputs.shape[0]):\n",
    "        if acc_outputs[i] == acc_y[i]:\n",
    "            acc += 1\n",
    "    \n",
    "    acc /= acc_outputs.shape[0]\n",
    "    \n",
    "    loss = loss_function(outputs,y)\n",
    "    \n",
    "    if train:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return acc, loss\n",
    "    # return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(size = 32, calc_acc = False):\n",
    "    random_start = np.random.randint(len(dev_data) - size)\n",
    "    X,y = dev_data[random_start:random_start+size], dev_labels[random_start:random_start+size]\n",
    "    with torch.no_grad():\n",
    "        val_acc, val_loss = fwd_pass(X,y, calc_acc = calc_acc)\n",
    "        # val_loss = fwd_pass(X,y, calc_acc = calc_acc)\n",
    "    return val_acc, val_loss\n",
    "    # return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-1593398654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[10]' is invalid for input of size 1240",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d4f8d932d69a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{MODEL_NAME},{round(time.time(),3)}, {round(float(acc),2)}, {round(float(loss[0]),4)}, {round(float(val_acc),2)}, {round(float(val_loss),4)} \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0;31m# f.write(f\"{MODEL_NAME},{round(time.time(),3)} \\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-d4f8d932d69a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfwd_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfwd_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-32d9dae0ed5b>\u001b[0m in \u001b[0;36mfwd_pass\u001b[0;34m(X, y, train, calc_acc)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#     if calc_acc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-0a0e2cdb18a4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mRelu1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mRelu2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRelu1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[10]' is invalid for input of size 1240"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "MODEL_NAME = f\"model-{int(time.time())}\"\n",
    "\n",
    "net = SimpleCNN(args.cnn_n1_kernel, args.cnn_n2_kernel, args.cnn_n3_kernel, args.cnn_n1_channels)\n",
    "optimizer = optim.Adam(net.parameters(), lr = args.learning_rate)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "print(MODEL_NAME)\n",
    "\n",
    "def train():\n",
    "    # BATCH_SIZE = 100 # 55 to 100 is fine\n",
    "    EPOCHS = 250 # 250 is fine right now\n",
    "    with open(\"model.log\", \"w\") as f:\n",
    "        for epoch in range(EPOCHS):\n",
    "            for i in tqdm(range(0,len(train_data), args.batch_size)):\n",
    "                batch_X = train_data[i:i+args.batch_size]\n",
    "                batch_y = train_labels[i:i+args.batch_size]\n",
    "                \n",
    "                acc, loss = fwd_pass(batch_X, batch_y, train = True)\n",
    "                loss = fwd_pass(batch_X, batch_y, train = True)\n",
    "                if i % 50 == 0:\n",
    "                    val_acc, val_loss = test(size = 1)                    \n",
    "                    # val_loss = test(size = 1)\n",
    "                    \n",
    "                    print(loss)\n",
    "                    \n",
    "                    f.write(f\"{MODEL_NAME},{round(time.time(),3)}, {round(float(acc),2)}, {round(float(loss[0]),4)}, {round(float(val_acc),2)}, {round(float(val_loss),4)} \\n\")\n",
    "                    # f.write(f\"{MODEL_NAME},{round(time.time(),3)} \\n\")\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "style.use(\"ggplot\")\n",
    "\n",
    "model_name = MODEL_NAME\n",
    "\n",
    "def create_acc_loss_graph(model_name):\n",
    "    contents = open(\"model.log\", \"r\").read().split('\\n')\n",
    "    \n",
    "    times = []\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    \n",
    "    val_accs = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for c in contents:\n",
    "        if model_name in c:\n",
    "            name, timestamp, acc, loss, val_acc, val_loss = c.split(\",\")\n",
    "            times.append(float(timestamp))\n",
    "            accuracies.append(float(acc))\n",
    "            losses.append(float(loss))\n",
    "            val_accs.append(float(val_acc))\n",
    "            val_losses.append(float(val_loss))\n",
    "            \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax1 = plt.subplot2grid((2,1),(0,0))\n",
    "    ax2 = plt.subplot2grid((2,1),(1,0), sharex = ax1)\n",
    "    \n",
    "    ax1.plot(times, accuracies, label = 'acc')\n",
    "    ax1.plot(times, val_accs, label = 'val_acc')\n",
    "    ax1.legend(loc = 2)\n",
    "    \n",
    "    ax2.plot(times, losses, label = 'loss')\n",
    "    ax2.plot(times, val_losses, label = 'val_losses')\n",
    "    ax2.legend(loc = 2)\n",
    "    plt.show()\n",
    "    \n",
    "create_acc_loss_graph(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Post Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pattern model to use in tandem with this (probably separate notebook)\n",
    "# Final predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
